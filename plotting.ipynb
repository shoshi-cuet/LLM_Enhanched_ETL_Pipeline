{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bar Plot - Time AdventureWorks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data and models\n",
    "models = ['Mistral 7B', 'Llama2 7B', 'Llama3 8B', 'Qwen2 7B']\n",
    "batch_size_8 = pd.read_csv('path/to/the/file/')\n",
    "batch_size_4 = pd.read_csv('path/to/the/file/')\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "width = 0.1  # bar width\n",
    "x = np.arange(len(models))\n",
    "\n",
    "ax.bar(x - 0.25, batch_size_8['W3'], width, label='Batch 8 W3', color='#1f77b4')\n",
    "ax.bar(x - 0.15, batch_size_8['W2'], width, label='Batch 8 W2', color='#2ca02c')\n",
    "ax.bar(x - 0.05, batch_size_8['W1'], width, label='Batch 8 W1', color='#d62728')\n",
    "ax.bar(x + 0.05, batch_size_4['W3'], width, label='Batch 4 W3', color='#9467bd')\n",
    "ax.bar(x + 0.15, batch_size_4['W2'], width, label='Batch 4 W2', color='#8c564b')\n",
    "ax.bar(x + 0.25, batch_size_4['W1'], width, label='Batch 4 W1', color='#e377c2')\n",
    "\n",
    "ax.set_ylabel('Time (minutes)')\n",
    "ax.set_title('Time to Fine-tune and Generate on AdventureWorks DataSet')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(models)\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    for j, (week, batch_8, batch_4) in enumerate(zip(['W3', 'W2', 'W1'], \n",
    "                                                     [batch_size_8['W3'][i], batch_size_8['W2'][i], batch_size_8['W1'][i]],\n",
    "                                                     [batch_size_4['W3'][i], batch_size_4['W2'][i], batch_size_4['W1'][i]])):\n",
    "        ax.text(i - 0.25 + j * 0.1, batch_8, str(batch_8), ha='center', va='bottom', fontsize=8)\n",
    "        ax.text(i + 0.05 + j * 0.1, batch_4, str(batch_4), ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bar Plot - Time NorthWind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data and models\n",
    "models = ['Mistral 7B', 'Llama2 7B', 'Llama3 8B', 'Qwen2 7B']\n",
    "batch_size_8 = pd.read_csv('path/to/the/file/')\n",
    "batch_size_4 = pd.read_csv('path/to/the/file/')\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "width = 0.1\n",
    "x = np.arange(len(models))\n",
    "\n",
    "ax.bar(x - 0.25, batch_size_8['W4'], width, label='Batch 8 W4', color='#1f77b4')\n",
    "ax.bar(x - 0.15, batch_size_8['W3'], width, label='Batch 8 W3', color='#2ca02c')\n",
    "ax.bar(x - 0.05, batch_size_8['W2'], width, label='Batch 8 W2', color='#d62728')\n",
    "ax.bar(x + 0.05, batch_size_8['W1'], width, label='Batch 8 W1', color='#9467bd')\n",
    "ax.bar(x + 0.15, batch_size_4['W4'], width, label='Batch 4 W4', color='#8c564b')\n",
    "ax.bar(x + 0.25, batch_size_4['W3'], width, label='Batch 4 W3', color='#e377c2')\n",
    "ax.bar(x + 0.35, batch_size_4['W2'], width, label='Batch 4 W2', color='#7f7f7f')\n",
    "ax.bar(x + 0.45, batch_size_4['W1'], width, label='Batch 4 W1', color='#bcbd22')\n",
    "\n",
    "ax.set_ylabel('Time (minutes)')\n",
    "ax.set_title('Time to Fine-tune and Generate on NorthWind DataSet')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(models)\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    for j, (week, batch_8, batch_4) in enumerate(zip(['W4', 'W3', 'W2', 'W1'], \n",
    "                                                     [batch_size_8['W4'][i], batch_size_8['W3'][i], batch_size_8['W2'][i], batch_size_8['W1'][i]],\n",
    "                                                     [batch_size_4['W4'][i], batch_size_4['W3'][i], batch_size_4['W2'][i], batch_size_4['W1'][i]])):\n",
    "        ax.text(i - 0.25 + j * 0.1, batch_8, str(batch_8), ha='center', va='bottom', fontsize=8)\n",
    "        ax.text(i + 0.05 + j * 0.1, batch_4, str(batch_4), ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Curve - AdventureWorks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_loss_adventure(param):\n",
    "    df = pd.read_csv(f'path/to/the/file/')\n",
    "    \n",
    "    models = ['Mistral_7B', 'Llama2_7B', 'Llama3_8B', 'Qwen2_7B']\n",
    "    window_sizes = [1, 2, 3]\n",
    "\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    for model in models:\n",
    "        for window in window_sizes:\n",
    "            train_col = f'{model}_B{param}_W{window}_Train'\n",
    "            val_col = f'{model}_B{param}_W{window}_Val'\n",
    "            if train_col in df.columns and val_col in df.columns:\n",
    "                plt.plot(df['Step'], df[train_col], label=f'{model} Train W{window}')\n",
    "                plt.plot(df['Step'], df[val_col], label=f'{model} Val W{window}', linestyle='--')\n",
    "\n",
    "    plt.title(f'AdventureWorks - Training and Validation Loss (Batch Size {param})', fontsize=16)\n",
    "    plt.xlabel('Steps', fontsize=16)\n",
    "    plt.ylabel('Loss', fontsize=16)\n",
    "    \n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=14)\n",
    "    plt.yscale('log')\n",
    "    plt.grid(True, which=\"both\", ls=\"-\", alpha=0.2)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_loss_adventure(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_loss_adventure(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Curve - NorthWind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_loss_nortwind(param):\n",
    "    df = pd.read_csv(f'path/to/the/file/')\n",
    "    models = ['Mistral_7B', 'Llama2_7B', 'Llama3_8B', 'Qwen2_7B']\n",
    "    window_sizes = [1, 2, 3]\n",
    "\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for model in models:\n",
    "        for window in window_sizes:\n",
    "            plt.plot(df['Step'], df[f'{model}_W{window}_Train'], label=f'{model} Train W{window}')\n",
    "            plt.plot(df['Step'], df[f'{model}_W{window}_Val'], label=f'{model} Val W{window}', linestyle='--')\n",
    "\n",
    "    plt.title(f'NorthWind - Training and Validation Loss (Batch Size {param})', fontsize=16)\n",
    "    plt.xlabel('Steps', fontsize=16)\n",
    "    plt.ylabel('Loss', fontsize=16)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=14)\n",
    "    plt.yscale('log')\n",
    "    plt.grid(True, which=\"both\", ls=\"-\", alpha=0.2)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_loss_nortwind(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_loss_nortwind(8)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
